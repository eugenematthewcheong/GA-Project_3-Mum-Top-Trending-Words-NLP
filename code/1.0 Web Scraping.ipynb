{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# DSI-SG-42\n",
    "## Project 3: Web APIs & NLP\n",
    "> Authors: Pius Yee, Conrad Aw, Eugene Matthew Cheong\n",
    "---\n",
    "## Introduction\n",
    "\n",
    "In today's fast-paced world, the role of a mother is more challenging and multifaceted than ever before. Mothers are not only caregivers but also significant contributors to the workforce. This is especially true in Singapore, where the workforce is the main driver of the economy. As the nation progresses, the competing demands of work and family life have placed immense pressure on working mothers, making it a topic of great importance and ongoing debate.\n",
    "\n",
    "Recent discussions have highlighted the need for more support for working mothers, despite the government's efforts to improve support systems. The challenges faced by working mothers in Singapore are unique due to the high expectations of productivity and efficiency in both professional and personal spheres. These challenges often lead to a struggle to maintain a healthy work-life balance, which can impact their well-being and that of their families.\n",
    "\n",
    "To better understand the difficulties faced by the current generation of new parents, particularly mothers, it is crucial to delve into their thoughts, concerns, and discussions. One effective way to do this is through web-scraping on anonymous platforms like Reddit, where many parents share their experiences, seek advice, and discuss various topics related to parenting and work-life balance.\n",
    "\n",
    "By analyzing the data collected from Reddit, we can identify the \"hot topics\" that are most relevant and pressing for working mothers. This information can provide valuable insights into the specific challenges they face, the kind of support they need, and the solutions that could be implemented to improve their situation. Ultimately, this project aims to shed light on the experiences of working mothers in Singapore, contributing to a better understanding of their needs and paving the way for more targeted and effective support measures.\n",
    "\n",
    "News Articles:\n",
    "- [Channel News Asia - Working Mum challenges](https://www.channelnewsasia.com/commentary/working-mums-challenges-best-tips-juggle-home-work-family-1373851)\n",
    "\n",
    "- [Nanyang Business School article - Importance of work Life balance for women](https://www.ntu.edu.sg/business/news-events/news/story-detail/what-work-life-balance-means-for-women)\n",
    "\n",
    "- [Straits Times - Subsidies for non-working mothers](https://www.straitstimes.com/singapore/smart-investment-to-give-lower-income-non-working-mums-more-childcare-subsidies)\n",
    "\n",
    "- [Channel News Asia - More support for middle class working mothers](https://www.channelnewsasia.com/singapore/budget-2023-debate-working-mothers-middle-class-cpf-ceiling-jobs-skills-integrators-3295851)\n",
    "\n",
    "- [What can government and employers do to support mothers](https://www.nytimes.com/2021/02/04/parenting/government-employer-support-moms.html)\n",
    "\n",
    "## Persona\n",
    "\n",
    "This is a Ministry of Social and Family Development (MSF) meeting. The Data Science team is presenting a structured, data-driven approach to keyword research so as to enhance digital campaigning efforts and improve visibility and engagement. The target audience are the Marketing Strategist and Campaign Strategist.\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "In light of the current generation's high engagement on social media and forums, particularly in discussions related to work-life balance and childcare, our Campaign Strategists face challenges in consistently identifying and categorizing relevant topics for our campaigns. This reliance on personal assumptions rather than empirical evidence hampers the effectiveness of our campaigns or programs, hindering our ability to optimize online presence and effectively reach our target audience. To address this challenge, we propose developing a classification model to accurately classify posts and forums relevant to mothers, thereby enhancing our campaign targeting and outreach strategies.\n",
    "\n",
    "## Table of Contents ##\n",
    "\n",
    "### 1.0 Data Collection ###\n",
    "\n",
    "[1.1 Import Packages](#1.1-import-packages)\n",
    "\n",
    "[1.2 Webscraping](#1.2-webscraping)\n",
    "\n",
    "[1.3 Selection of subreddits](#1.3-selection-of-subreddits)\n",
    "\n",
    "[1.4 Code for text scraping](#1.4-code-for-text-scraping)\n",
    "\n",
    "### [2. Data Cleaning, Preprocessing and EDA](./2.0%20Data%20Cleaning%20&%20Preprocessing.ipynb)\n",
    "\n",
    "[2.1 Import CSV file](./2.0%20Data%20Cleaning%20&%20Preprocessing.ipynb)\n",
    "\n",
    "[2.2 Data cleaning](./2.0%20Data%20Cleaning%20&%20Preprocessing.ipynb)\n",
    "\n",
    "[2.3 Preprocessing](./2.0%20Data%20Cleaning%20&%20Preprocessing.ipynb)\n",
    "\n",
    "[2.4 Exploratory Data Analysis (EDA)](./2.0%20Data%20Cleaning%20&%20Preprocessing.ipynb)\n",
    "\n",
    "### [3. Modelling, Evaluation and Tuning](./3.0%20Modelling.ipynb)\n",
    "\n",
    "[3.1 Import CSV file](./3.0%20Modelling.ipynb)\n",
    "\n",
    "[3.2 Splitting of train/test data](./3.0%20Modelling.ipynb)\n",
    "\n",
    "[3.3 Modelling](./3.0%20Modelling.ipynb)\n",
    "\n",
    "[3.4 Model Selection](./3.0%20Modelling.ipynb)\n",
    "\n",
    "[3.5 AUC-ROC](./3.0%20Modelling.ipynb)\n",
    "\n",
    "[3.6 Save it as Pickle](./3.0%20Modelling.ipynb)\n",
    "\n",
    "[3.7 Recommendations](./3.0%20Modelling.ipynb)\n",
    "\n",
    "[3.8 Conclusion](./3.0%20Modelling.ipynb)\n",
    "\n",
    "### [4. Model Testing](./4.0%20Model%20Test.ipynb)\n",
    "\n",
    "[4.1 Scraping Input Reddit](./4.0%20Model%20Test.ipynb)\n",
    "\n",
    "[4.2 Cleaning Data](./4.0%20Model%20Test.ipynb)\n",
    "\n",
    "[4.3 Tokenizing with Regex](./4.0%20Model%20Test.ipynb)\n",
    "\n",
    "[4.4 Stop Word Removal](./4.0%20Model%20Test.ipynb)\n",
    "\n",
    "[4.5 Lemmatization](./4.0%20Model%20Test.ipynb)\n",
    "\n",
    "[4.6 Run the model](./4.0%20Model%20Test.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the project requirements, webscraping will be conducted on two subreddits as part of the solution formation. We will be using the official Reddit API that will require initialization before the webscraping activity is conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Reddit instance with your API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id='YheGGNwn1zlIePJLrJZZYw',\n",
    "    client_secret='JWe8I5cM8YCZGowmL_WPe1d-UuXuFw',\n",
    "    user_agent='eumattbro'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Selection of subreddit\n",
    "\n",
    "Characteristics considered during the selection process:\n",
    "\n",
    "1) **Relevance**: The discussions and subjects in the subreddit must be relevant to Mothers and Fathers as these are the main protagonist of our target group.\n",
    "\n",
    "2) **Activity & Engagement Level**: The subreddit needs to be active and engaging based on the number of posts and comments as higher activity levels may provide more interesting data for analysis.\n",
    "\n",
    "3) **Size**: The member size of the subreddit is important as larger subreddits may have more diverse content and discussions while smaller subreddits may have more focused discussions on specific topics.\n",
    "\n",
    "4) **Moderation**: Strong moderation preferred to ensure fewer spam or irrelevant posts.\n",
    "\n",
    "4) **Quality of Content**: Quality of content based on post and comments level of detail and informativeness.\n",
    "\n",
    "5) **Variety**: Consider selecting a mix of subreddits to get a diverse range of content and perspectives.\n",
    "\n",
    "\n",
    "Based on the above mentioned characteristics, we identified **r/daddit** and **r/Mommit** for scraping. One of the main reason was also that mommit and daddit had more positive sentiments in the analysis and upon further reading, we noted that the discussiosn made in the posts were relevant respectively and it was easier to distinguish both. this is aligned with the sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_reddits = [\"daddit\", \"Mommit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Code for text scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create code to collect and organize data from **r/Mommit** and **r/daddit** posts and their comments into a structured format suitable for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function that takes a list of comments and a dictionary as arguments.\n",
    "def print_comments(comments, comment_dict):\n",
    "    # For each comment in the list, pause for 0.1 seconds to avoid tiriggering rate limits\n",
    "    for comment in comments:\n",
    "        time.sleep(0.1)\n",
    "        # Append the comment's body text to comment_dict\n",
    "        comment_dict.append(comment.body)\n",
    "        # If the comment has replies, appends the replies to comment_dict and recursively calls itself to process these replies.\n",
    "        if len(comment.replies) > 0:\n",
    "            comment_dict.append(comment.replies)\n",
    "            print_comments(comment.replies, comment_dict)\n",
    "\n",
    "# Create ext list\n",
    "ext = []\n",
    "for sub_reddit in sub_reddits:\n",
    "    # iterates over a list of subreddit names (sub_reddits). For each subreddit, fetch up to 1000 hot submissions.\n",
    "    for submission in reddit.subreddit(sub_reddit).hot(limit=1000):\n",
    "        # For each submission, create a dictionary containing the subreddit name, post title, self-text, score, and URL.\n",
    "        post_data = ({\n",
    "            \"subreddit\": sub_reddit,\n",
    "            \"title\": submission.title,\n",
    "            \"selftext\": submission.selftext,\n",
    "            \"score\": submission.score,\n",
    "            \"url\": submission.url,\n",
    "            })\n",
    "\n",
    "        # Replace the placeholder comments (used for loading additional comments) with actual comments\n",
    "        submission.comments.replace_more(limit=None)\n",
    "        post_data['comments'] = []\n",
    "\n",
    "        print_comments(submission.comments, post_data['comments']) \n",
    "\n",
    "\n",
    "        ext.append(post_data)\n",
    "# Create pandas dataframe\n",
    "web_df = pd.DataFrame(ext)\n",
    "\n",
    "web_df.to_csv('../datasets/daddit_mommit_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Notebok: [2.0 Data Cleaning and Preprocessing](./2.0%20Data%20Cleaning%20&%20Preprocessing.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
